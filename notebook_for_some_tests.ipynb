{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Kernel_methods_Challenge_starting.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lSwKq2AT4uzy",
        "7cQctdgW6M0i",
        "KiI-13xV4sNR",
        "ZIzK3SWqVK5w"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDesYz9ZxKyV"
      },
      "source": [
        "# Kernel Methods Data Challenge\n",
        "\n",
        "Authors:\n",
        "\n",
        "Breno BALDAS SKUK & Samuel ASSERPE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJPR2X-pxeeI"
      },
      "source": [
        "# 1. Downloading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwSPZSI9snDZ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import linalg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCm9RdLixGRa",
        "outputId": "204a4d50-b0d3-4fda-bdaa-2bfd8f988e46"
      },
      "source": [
        "# download data from google drive if in google colab\n",
        "google_colab = False\n",
        "data_dir = \"\"\n",
        "if google_colab:\n",
        "  from google.colab import files\n",
        "  from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "  gdd.download_file_from_google_drive(file_id='1um-WlzyVqtTrJ0AQ2LX28Ailj-yLgme8',\n",
        "                                    dest_path='./data.zip',\n",
        "                                    unzip=True)\n",
        "\n",
        "  # delete the .zip and readme\n",
        "  !rm './data.zip'\n",
        "\n",
        "else:\n",
        "  data_dir = \"data/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1um-WlzyVqtTrJ0AQ2LX28Ailj-yLgme8 into ./data.zip... Done.\n",
            "Unzipping...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QYQr940xJJu"
      },
      "source": [
        "# 1st dataset\n",
        "df_train_labels_0 = pd.read_csv(data_dir+\"Ytr0.csv\")\n",
        "train_labels_0 = np.ravel(df_train_labels_0['Bound'].to_numpy())\n",
        "\n",
        "# 2nd dataset \n",
        "df_train_labels_1 = pd.read_csv(data_dir+\"Ytr1.csv\")\n",
        "train_labels_1 = np.ravel(df_train_labels_1['Bound'].to_numpy())\n",
        "\n",
        "# 3rd dataset\n",
        "df_train_labels_2 = pd.read_csv(data_dir+\"Ytr2.csv\")\n",
        "train_labels_2 = np.ravel(df_train_labels_2['Bound'].to_numpy())\n",
        "\n",
        "\n",
        "# Load precomputed matrices\n",
        "\n",
        "cols = [str(i) for i in range(100)] # create some col names\n",
        "\n",
        "# 1st dataset\n",
        "Xtr0_mat = pd.read_csv(data_dir+\"Xtr0_mat100.csv\", sep=\"\\s+|;|:\", names=cols, header=None, engine=\"python\").to_numpy()\n",
        "Xte0_mat = pd.read_csv(data_dir+\"Xte0_mat100.csv\", sep=\"\\s+|;|:\", names=cols, header=None, engine=\"python\").to_numpy()\n",
        "\n",
        "# 2nd dataset\n",
        "Xtr1_mat = pd.read_csv(data_dir+\"Xtr1_mat100.csv\", sep=\"\\s+|;|:\", names=cols, header=None, engine=\"python\").to_numpy()\n",
        "Xte1_mat = pd.read_csv(data_dir+\"Xte1_mat100.csv\", sep=\"\\s+|;|:\", names=cols, header=None, engine=\"python\").to_numpy()\n",
        "\n",
        "# 3rd dataset\n",
        "Xtr2_mat = pd.read_csv(data_dir+\"Xtr2_mat100.csv\", sep=\"\\s+|;|:\", names=cols, header=None, engine=\"python\").to_numpy()\n",
        "Xte2_mat = pd.read_csv(data_dir+\"Xte2_mat100.csv\", sep=\"\\s+|;|:\", names=cols, header=None, engine=\"python\").to_numpy()\n",
        "\n",
        "# reading the raw data with pandas\n",
        "\n",
        "# 1st dataset\n",
        "Xtr0 = pd.read_csv(data_dir+\"Xtr0.csv\")\n",
        "Xtr0=Xtr0['seq'].tolist()\n",
        "\n",
        "Xte0 = pd.read_csv(data_dir+\"Xte0.csv\")\n",
        "Xte0=Xte0['seq'].tolist()\n",
        "\n",
        "# 2nd dataset\n",
        "Xtr1 = pd.read_csv(data_dir+\"Xtr1.csv\")\n",
        "Xtr1=Xtr1['seq'].tolist()\n",
        "\n",
        "Xte1 = pd.read_csv(data_dir+\"Xte1.csv\")\n",
        "Xte1=Xte1['seq'].tolist()\n",
        "\n",
        "# 3rd dataset\n",
        "Xtr2 = pd.read_csv(data_dir+\"Xtr2.csv\")\n",
        "Xtr2=Xtr2['seq'].tolist()\n",
        "\n",
        "Xte2 = pd.read_csv(data_dir+\"Xte2.csv\")\n",
        "Xte2=Xte2['seq'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wPQI5EUxla5"
      },
      "source": [
        "# 2. Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ssr_q4fCsnDk"
      },
      "source": [
        "def export_predict(pred_1,pred_2,pred_3,file_name):\n",
        "    preds = pd.DataFrame({'Id':np.array(range(3000)),'Bound':np.concatenate([pred_1,pred_2,pred_3])})\n",
        "    preds.to_csv(file_name,index=False)\n",
        "\n",
        "\n",
        "def ensure_2D(array):\n",
        "\n",
        "    # If input is scalar raise error\n",
        "    if array.ndim == 0:\n",
        "        raise ValueError(\n",
        "            \"Expected 2D array, got scalar array instead:\\narray={}.\\n\"\n",
        "            \"Reshape your data either using array.reshape(-1, 1) if \"\n",
        "            \"your data has a single feature or array.reshape(1, -1) \"\n",
        "            \"if it contains a single sample.\".format(array))\n",
        "    # If input is 1D raise error\n",
        "    if array.ndim == 1:\n",
        "        raise ValueError(\n",
        "            \"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\n",
        "            \"Reshape your data either using array.reshape(-1, 1) if \"\n",
        "            \"your data has a single feature or array.reshape(1, -1) \"\n",
        "            \"if it contains a single sample.\".format(array))\n",
        "        \n",
        "def check_y(X, y):\n",
        "\n",
        "    y = y.reshape(-1)\n",
        "    if len(y) != len(X):\n",
        "      raise ValueError(\n",
        "            \"Expected arrayof shape ({},) or ({},1). Got instead:\\narray={}.\"\n",
        "            .format(len(X), len(X), array))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3SSSKfysnDq"
      },
      "source": [
        "\n",
        "def train_test_split(X, y, train_frac=0.75):\n",
        "    \n",
        "    shuffle = np.random.permutation(len(X))\n",
        "    last_train = int(train_frac*len(X))\n",
        "    \n",
        "    X_rnd = X[shuffle]\n",
        "    y_rnd = y[shuffle]\n",
        "\n",
        "    return X_rnd[:last_train], y_rnd[:last_train], X_rnd[last_train:], y_rnd[last_train:]\n",
        "\n",
        "\n",
        "def train_test_split_on_gram(K, y, train_frac=0.75):\n",
        "\n",
        "    shuffle = np.random.permutation(len(K))\n",
        "    last_train = int(train_frac*len(K))\n",
        "    idxs_train = shuffle[:last_train]\n",
        "    idxs_test = shuffle[last_train:]\n",
        "\n",
        "    K_train = K[idxs_train].T[idxs_train].T\n",
        "    K_test_train = K[idxs_test].T[idxs_train].T\n",
        "\n",
        "    return K_train, y[idxs_train], K_test_train, y[idxs_test]\n",
        "\n",
        "\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    assert len(y_true) == len(y_pred)\n",
        "    return np.sum(y_true == y_pred) / len(y_true)\n",
        "\n",
        "\n",
        "\n",
        "def remap_zero_minus_one(y):\n",
        "    new_y = y.copy()\n",
        "    new_y[y==0] = -1\n",
        "    return new_y\n",
        "\n",
        "def remap_minus_one_zero(y):\n",
        "    new_y = y.copy()\n",
        "    new_y[y==-1] = 0\n",
        "    return new_y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8NPefAYsnDl"
      },
      "source": [
        "# 3. Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K_QoPxDsnDm"
      },
      "source": [
        "\n",
        "\n",
        "#Ridge without kernel\n",
        "def ridgeEstimator(X,y,lambd):\n",
        "    \"\"\"\n",
        "    Params:\n",
        "    ######\n",
        "    X      is a (n_samples, n_features) array : the training inputs\n",
        "    y      is a (n_samples,) array : the training labels\n",
        "    lambd  is a postive scalar (regularization term)\n",
        "\n",
        "    Returns:\n",
        "    ######\n",
        "    theta : a (n_features,) array. The parameters of the linear model estimation\n",
        "    \"\"\"\n",
        "    \n",
        "    # check size of X\n",
        "    ensure_2D(X)\n",
        "    # check size of y\n",
        "    check_y(X,y)\n",
        "\n",
        "    # the labels must be {-1,+1}\n",
        "    y = remap_zero_minus_one(y)\n",
        "    \n",
        "    (n,d) = X.shape\n",
        "    # decide to invert a (n,n) or a (d,d) matrix\n",
        "    if d <= n: # standard ridge regression\n",
        "    \n",
        "        # compute the ridge estimator\n",
        "        cov = X.T @ X\n",
        "        reg = lambd * n * np.eye(d)\n",
        "\n",
        "        theta = linalg.solve( cov+reg , X.T @ y ) # résout le système linéaire\n",
        "    \n",
        "    else: # kernel ridge regression with a linear kernel\n",
        "\n",
        "        gram = X @ X.T\n",
        "        reg = lambd * n * np.eye(n)\n",
        "\n",
        "        theta = X.T @ linalg.solve( gram+reg , y ) # résout le système linéaire\n",
        "\n",
        "    return theta\n",
        "\n",
        "\n",
        "def predictLinear(X, theta):\n",
        "\n",
        "    # check size of X\n",
        "    ensure_2D(X)\n",
        "    # linear prediction\n",
        "    preds = np.sign(X @ theta).astype(int)\n",
        "    # remap {-1,1} to {0,1}\n",
        "    preds = remap_minus_one_zero(preds)\n",
        "\n",
        "    return preds\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSwKq2AT4uzy"
      },
      "source": [
        "## Test classic ridge regression and hyperparameter research"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd5arkYtfBTa",
        "outputId": "cdb05787-a83a-4005-ddf4-7af1f2d8ebf6"
      },
      "source": [
        "### Test classic ridge regression and hyperparameter research\n",
        "\n",
        "n_iter = 100\n",
        "\n",
        "# center the design matrix\n",
        "(n,d) = Xtr0_mat.shape\n",
        "means = np.ones(n) @ Xtr0_mat / n\n",
        "Xtr0_mat_c = Xtr0_mat - means\n",
        "\n",
        "for lambd in [1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2]: # tout est un peu équivalent\n",
        "\n",
        "  acc_train = 0\n",
        "  acc_valid = 0\n",
        "  \n",
        "  for it in range(n_iter):\n",
        "    X_train, y_train, X_valid, y_valid = train_test_split(Xtr0_mat_c, train_labels_0, train_frac=0.75)\n",
        "\n",
        "    #ridge predictions:\n",
        "    theta = ridgeEstimator(X_train, y_train, lambd=lambd)\n",
        "    y_train_pred = predictLinear(X_train,theta)\n",
        "    y_valid_pred = predictLinear(X_valid,theta)\n",
        "\n",
        "    # evaluation\n",
        "    acc_train += accuracy(y_train, y_train_pred)\n",
        "    acc_valid += accuracy(y_valid, y_valid_pred)\n",
        "  \n",
        "  acc_train /= n_iter\n",
        "  acc_valid /= n_iter\n",
        "\n",
        "  print(\"\\nWith lambda = {}\\n\".format(lambd))\n",
        "  print(\"Accuracy on the train set : {} %\".format((100 * acc_train)))\n",
        "  print(\"Accuracy on the validation set : {} %\".format((100 * acc_valid)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "With lambda = 1e-08\n",
            "\n",
            "Accuracy on the train set : 66.23266666666669 %\n",
            "Accuracy on the validation set : 58.777999999999984 %\n",
            "\n",
            "With lambda = 1e-07\n",
            "\n",
            "Accuracy on the train set : 66.22933333333333 %\n",
            "Accuracy on the validation set : 58.46000000000002 %\n",
            "\n",
            "With lambda = 1e-06\n",
            "\n",
            "Accuracy on the train set : 66.11533333333334 %\n",
            "Accuracy on the validation set : 58.92400000000002 %\n",
            "\n",
            "With lambda = 1e-05\n",
            "\n",
            "Accuracy on the train set : 65.99000000000001 %\n",
            "Accuracy on the validation set : 58.67600000000001 %\n",
            "\n",
            "With lambda = 0.0001\n",
            "\n",
            "Accuracy on the train set : 64.64533333333334 %\n",
            "Accuracy on the validation set : 59.233999999999995 %\n",
            "\n",
            "With lambda = 0.001\n",
            "\n",
            "Accuracy on the train set : 62.84866666666669 %\n",
            "Accuracy on the validation set : 58.42 %\n",
            "\n",
            "With lambda = 0.01\n",
            "\n",
            "Accuracy on the train set : 62.165333333333315 %\n",
            "Accuracy on the validation set : 58.240000000000016 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cQctdgW6M0i"
      },
      "source": [
        "## Sklearn Ridge regression results for comparaison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMPSZevq6RHd",
        "outputId": "8c439f34-d243-4904-d3a8-7d62c7373bc0"
      },
      "source": [
        "### Compare with sklearn's ridge regression\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "n_iter = 100\n",
        "\n",
        "for lambd in [1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2]: # tout est un peu équivalent\n",
        "\n",
        "  acc_train = 0\n",
        "  acc_valid = 0\n",
        "  \n",
        "  for it in range(n_iter):\n",
        "    X_train, y_train, X_valid, y_valid = train_test_split(Xtr0_mat_c, train_labels_0, train_frac=0.75)\n",
        "\n",
        "    #ridge predictions:\n",
        "    clf = Ridge(alpha=lambd * len(X_train), fit_intercept=False).fit(X_train, remap_zero_minus_one(y_train))\n",
        "    y_train_pred = remap_minus_one_zero(np.sign(clf.predict(X_train)).astype(int))\n",
        "    y_valid_pred = remap_minus_one_zero(np.sign(clf.predict(X_valid)).astype(int))\n",
        "\n",
        "    # evaluation\n",
        "    acc_train += accuracy(y_train, y_train_pred)\n",
        "    acc_valid += accuracy(y_valid, y_valid_pred)\n",
        "  \n",
        "  acc_train /= n_iter\n",
        "  acc_valid /= n_iter\n",
        "\n",
        "  print(\"\\nWith lambda = {}\\n\".format(lambd))\n",
        "  print(\"Accuracy on the train set : {} %\".format((100 * acc_train)))\n",
        "  print(\"Accuracy on the validation set : {} %\".format((100 * acc_valid)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "With lambda = 1e-08\n",
            "\n",
            "Accuracy on the train set : 66.17133333333335 %\n",
            "Accuracy on the validation set : 58.90600000000003 %\n",
            "\n",
            "With lambda = 1e-07\n",
            "\n",
            "Accuracy on the train set : 66.0153333333333 %\n",
            "Accuracy on the validation set : 58.95000000000002 %\n",
            "\n",
            "With lambda = 1e-06\n",
            "\n",
            "Accuracy on the train set : 66.26800000000001 %\n",
            "Accuracy on the validation set : 58.79199999999999 %\n",
            "\n",
            "With lambda = 1e-05\n",
            "\n",
            "Accuracy on the train set : 66.12133333333333 %\n",
            "Accuracy on the validation set : 58.928000000000026 %\n",
            "\n",
            "With lambda = 0.0001\n",
            "\n",
            "Accuracy on the train set : 64.71866666666668 %\n",
            "Accuracy on the validation set : 59.075999999999986 %\n",
            "\n",
            "With lambda = 0.001\n",
            "\n",
            "Accuracy on the train set : 62.751333333333335 %\n",
            "Accuracy on the validation set : 59.01399999999999 %\n",
            "\n",
            "With lambda = 0.01\n",
            "\n",
            "Accuracy on the train set : 62.042000000000016 %\n",
            "Accuracy on the validation set : 58.638 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_aDkJq8snDo"
      },
      "source": [
        "# 4. KERNEL Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVMa35Lo1GtL"
      },
      "source": [
        "### Kernels on the matrix representation\n",
        "\n",
        "\n",
        "### GAUSSIAN KERNEL\n",
        "def gaussian_kernel(x, y, gamma=1):\n",
        "    return np.exp(-gamma * np.sum((x - y)**2))\n",
        "\n",
        "### LAPLACIAN KERNEL\n",
        "def laplacian_kernel(x, y, gamma=1):\n",
        "    return np.exp(-gamma * np.sum(abs(x - y)))\n",
        "\n",
        "### POLYNOMIAL KERNEL\n",
        "def ploynomial_kernel(x, y, d=3, gamma=1, c=1):\n",
        "    return (gamma * x@y + c)**d\n",
        "\n",
        "    \n",
        "############################### K MATRICES ####################################\n",
        "\n",
        "\n",
        "def compute_gram_from_kernel(X1,X2, kernel_func, params):\n",
        "    n1 = len(X1)\n",
        "    n2 = len(X2)\n",
        "    K = np.zeros((n1,n2))\n",
        "    for i in range(n1):\n",
        "        for j in range(n2):\n",
        "            K[i][j] = kernel_func(X1[i],X2[j], params)\n",
        "    return K\n",
        "\n",
        "\n",
        "########################################## KRR #################################\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcKGy56_snDo"
      },
      "source": [
        "\n",
        "def kernelRidgeEstimator(K,y,lambd):\n",
        "    \"\"\"\n",
        "    Params:\n",
        "    ######\n",
        "    K : (n_samples, n_samples) array. Kernel matrix of the input training data\n",
        "    y : (n_samples,) array. Training labels\n",
        "    lambd : positive scalar. Regularization parameter\n",
        "    \n",
        "    Returns:\n",
        "    ######\n",
        "    alpha : (n_samples,) array. The weights to give to each training data point.\n",
        "    \"\"\"\n",
        "    n = len(K)\n",
        "\n",
        "    # the labels must be {-1,+1}\n",
        "    y = remap_zero_minus_one(y)\n",
        "\n",
        "    reg = lambd * n * np.eye(n)\n",
        "    \n",
        "    alpha = linalg.solve( K + reg , y ) # solve the linear system\n",
        "    \n",
        "    return alpha\n",
        "\n",
        "def predict_from_gram(K_test_train, alpha):\n",
        "\n",
        "    preds = np.sign(K_test_train @ alpha).astype(int)\n",
        "    \n",
        "    # remap {-1,1} to {0,1}\n",
        "    preds = remap_minus_one_zero(preds)\n",
        "  \n",
        "    return preds\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiI-13xV4sNR"
      },
      "source": [
        "## Test KRR with gaussian kernel (and hyperparameters research)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gzekg8_3fBQ6",
        "outputId": "9422ffe1-06e1-4355-ab2a-68690e1fbd1e"
      },
      "source": [
        "# Test KRR with gaussian kernel (and hyperparameters research)\n",
        "\n",
        "need_to_compute_Grams = False\n",
        "\n",
        "if need_to_compute_Grams: # take a long time with actual implementation of the Gaussian gram matrix\n",
        "  Grams = []\n",
        "  gammas = [1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]\n",
        "\n",
        "  for gamma in gammas:\n",
        "\n",
        "    Grams.append( compute_gram_matrix(Xtr0_mat, Xtr0_mat, gaussian_kernel, gamma) )\n",
        "\n",
        "\n",
        "n_iter = 100\n",
        "\n",
        "for i in range(len(gammas)):\n",
        "\n",
        "  # global gram matrix\n",
        "  K = Grams[i]\n",
        "\n",
        "  # center the Gram matrix\n",
        "  n = len(K)\n",
        "  I = np.eye(n)\n",
        "  U = np.ones((n,n)) / n\n",
        "  K = (I-U) @ K @ (I-U)\n",
        "\n",
        "  print(\"####################\\n\\nWith a gaussian kernel of parameter gamma = {}\\n\\n####################\".format(gammas[i]))\n",
        "\n",
        "  for lambd in [1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2]: \n",
        "\n",
        "    acc_train = 0\n",
        "    acc_valid = 0\n",
        "    \n",
        "    for it in range(n_iter):\n",
        "      K_train, y_train, K_valid_train, y_valid = train_test_split_on_gram(K, train_labels_0, train_frac=0.75)\n",
        "\n",
        "      #KRR predictions:\n",
        "      alpha = kernelRidgeEstimator(K_train, y_train, lambd=lambd)\n",
        "      y_train_pred = predict_from_gram(K_train, alpha)\n",
        "      y_valid_pred = predict_from_gram(K_valid_train, alpha)\n",
        "\n",
        "      # evaluation\n",
        "      acc_train += accuracy(y_train, y_train_pred)\n",
        "      acc_valid += accuracy(y_valid, y_valid_pred)\n",
        "    \n",
        "    acc_train /= n_iter\n",
        "    acc_valid /= n_iter\n",
        "\n",
        "    print(\"\\nWith lambda = {}\\n\".format(lambd))\n",
        "    print(\"Accuracy on the train set : {} %\".format((100 * acc_train)))\n",
        "    print(\"Accuracy on the validation set : {} %\".format((100 * acc_valid)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "####################\n",
            "\n",
            "With a gaussian kernel of parameter gamma = 0.001\n",
            "\n",
            "####################\n",
            "\n",
            "With lambda = 1e-08\n",
            "\n",
            "Accuracy on the train set : 66.10333333333334 %\n",
            "Accuracy on the validation set : 58.79999999999998 %\n",
            "\n",
            "With lambda = 1e-07\n",
            "\n",
            "Accuracy on the train set : 65.28199999999998 %\n",
            "Accuracy on the validation set : 59.297999999999995 %\n",
            "\n",
            "With lambda = 1e-06\n",
            "\n",
            "Accuracy on the train set : 63.266 %\n",
            "Accuracy on the validation set : 59.07800000000003 %\n",
            "\n",
            "With lambda = 1e-05\n",
            "\n",
            "Accuracy on the train set : 62.19733333333334 %\n",
            "Accuracy on the validation set : 58.782000000000025 %\n",
            "\n",
            "With lambda = 0.0001\n",
            "\n",
            "Accuracy on the train set : 62.15133333333333 %\n",
            "Accuracy on the validation set : 58.184000000000005 %\n",
            "\n",
            "With lambda = 0.001\n",
            "\n",
            "Accuracy on the train set : 61.84933333333335 %\n",
            "Accuracy on the validation set : 58.147999999999996 %\n",
            "\n",
            "With lambda = 0.01\n",
            "\n",
            "Accuracy on the train set : 61.87133333333335 %\n",
            "Accuracy on the validation set : 58.156000000000006 %\n",
            "####################\n",
            "\n",
            "With a gaussian kernel of parameter gamma = 0.01\n",
            "\n",
            "####################\n",
            "\n",
            "With lambda = 1e-08\n",
            "\n",
            "Accuracy on the train set : 66.38666666666668 %\n",
            "Accuracy on the validation set : 59.019999999999996 %\n",
            "\n",
            "With lambda = 1e-07\n",
            "\n",
            "Accuracy on the train set : 65.94799999999996 %\n",
            "Accuracy on the validation set : 59.04200000000001 %\n",
            "\n",
            "With lambda = 1e-06\n",
            "\n",
            "Accuracy on the train set : 65.42933333333332 %\n",
            "Accuracy on the validation set : 58.652000000000015 %\n",
            "\n",
            "With lambda = 1e-05\n",
            "\n",
            "Accuracy on the train set : 63.308 %\n",
            "Accuracy on the validation set : 58.87 %\n",
            "\n",
            "With lambda = 0.0001\n",
            "\n",
            "Accuracy on the train set : 62.20066666666666 %\n",
            "Accuracy on the validation set : 58.294000000000004 %\n",
            "\n",
            "With lambda = 0.001\n",
            "\n",
            "Accuracy on the train set : 61.79400000000002 %\n",
            "Accuracy on the validation set : 58.21000000000001 %\n",
            "\n",
            "With lambda = 0.01\n",
            "\n",
            "Accuracy on the train set : 61.950000000000024 %\n",
            "Accuracy on the validation set : 58.168000000000006 %\n",
            "####################\n",
            "\n",
            "With a gaussian kernel of parameter gamma = 0.1\n",
            "\n",
            "####################\n",
            "\n",
            "With lambda = 1e-08\n",
            "\n",
            "Accuracy on the train set : 81.97333333333334 %\n",
            "Accuracy on the validation set : 59.57199999999997 %\n",
            "\n",
            "With lambda = 1e-07\n",
            "\n",
            "Accuracy on the train set : 69.25466666666665 %\n",
            "Accuracy on the validation set : 58.75399999999998 %\n",
            "\n",
            "With lambda = 1e-06\n",
            "\n",
            "Accuracy on the train set : 66.38733333333332 %\n",
            "Accuracy on the validation set : 59.04999999999999 %\n",
            "\n",
            "With lambda = 1e-05\n",
            "\n",
            "Accuracy on the train set : 65.50200000000001 %\n",
            "Accuracy on the validation set : 59.06400000000001 %\n",
            "\n",
            "With lambda = 0.0001\n",
            "\n",
            "Accuracy on the train set : 63.225333333333325 %\n",
            "Accuracy on the validation set : 59.03400000000002 %\n",
            "\n",
            "With lambda = 0.001\n",
            "\n",
            "Accuracy on the train set : 62.20466666666664 %\n",
            "Accuracy on the validation set : 58.317999999999984 %\n",
            "\n",
            "With lambda = 0.01\n",
            "\n",
            "Accuracy on the train set : 62.03266666666667 %\n",
            "Accuracy on the validation set : 58.48800000000001 %\n",
            "####################\n",
            "\n",
            "With a gaussian kernel of parameter gamma = 1.0\n",
            "\n",
            "####################\n",
            "\n",
            "With lambda = 1e-08\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 57.14800000000001 %\n",
            "\n",
            "With lambda = 1e-07\n",
            "\n",
            "Accuracy on the train set : 98.97733333333329 %\n",
            "Accuracy on the validation set : 58.50199999999999 %\n",
            "\n",
            "With lambda = 1e-06\n",
            "\n",
            "Accuracy on the train set : 81.85933333333331 %\n",
            "Accuracy on the validation set : 59.45399999999999 %\n",
            "\n",
            "With lambda = 1e-05\n",
            "\n",
            "Accuracy on the train set : 69.054 %\n",
            "Accuracy on the validation set : 59.45800000000001 %\n",
            "\n",
            "With lambda = 0.0001\n",
            "\n",
            "Accuracy on the train set : 65.80733333333335 %\n",
            "Accuracy on the validation set : 59.02000000000002 %\n",
            "\n",
            "With lambda = 0.001\n",
            "\n",
            "Accuracy on the train set : 63.39200000000002 %\n",
            "Accuracy on the validation set : 58.995999999999995 %\n",
            "\n",
            "With lambda = 0.01\n",
            "\n",
            "Accuracy on the train set : 62.13000000000002 %\n",
            "Accuracy on the validation set : 58.477999999999994 %\n",
            "####################\n",
            "\n",
            "With a gaussian kernel of parameter gamma = 10.0\n",
            "\n",
            "####################\n",
            "\n",
            "With lambda = 1e-08\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 57.09599999999999 %\n",
            "\n",
            "With lambda = 1e-07\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 57.025999999999975 %\n",
            "\n",
            "With lambda = 1e-06\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 57.47400000000001 %\n",
            "\n",
            "With lambda = 1e-05\n",
            "\n",
            "Accuracy on the train set : 99.04999999999998 %\n",
            "Accuracy on the validation set : 58.80399999999999 %\n",
            "\n",
            "With lambda = 0.0001\n",
            "\n",
            "Accuracy on the train set : 81.39666666666663 %\n",
            "Accuracy on the validation set : 59.31399999999998 %\n",
            "\n",
            "With lambda = 0.001\n",
            "\n",
            "Accuracy on the train set : 68.40333333333334 %\n",
            "Accuracy on the validation set : 59.553999999999995 %\n",
            "\n",
            "With lambda = 0.01\n",
            "\n",
            "Accuracy on the train set : 63.99133333333333 %\n",
            "Accuracy on the validation set : 59.108000000000004 %\n",
            "####################\n",
            "\n",
            "With a gaussian kernel of parameter gamma = 100.0\n",
            "\n",
            "####################\n",
            "\n",
            "With lambda = 1e-08\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 59.11799999999998 %\n",
            "\n",
            "With lambda = 1e-07\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 59.258000000000024 %\n",
            "\n",
            "With lambda = 1e-06\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 59.455999999999975 %\n",
            "\n",
            "With lambda = 1e-05\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 59.227999999999994 %\n",
            "\n",
            "With lambda = 0.0001\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 59.667999999999985 %\n",
            "\n",
            "With lambda = 0.001\n",
            "\n",
            "Accuracy on the train set : 97.15600000000005 %\n",
            "Accuracy on the validation set : 60.528000000000006 %\n",
            "\n",
            "With lambda = 0.01\n",
            "\n",
            "Accuracy on the train set : 79.10066666666667 %\n",
            "Accuracy on the validation set : 60.68399999999998 %\n",
            "####################\n",
            "\n",
            "With a gaussian kernel of parameter gamma = 1000.0\n",
            "\n",
            "####################\n",
            "\n",
            "With lambda = 1e-08\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 49.306000000000004 %\n",
            "\n",
            "With lambda = 1e-07\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 49.026 %\n",
            "\n",
            "With lambda = 1e-06\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 49.33200000000001 %\n",
            "\n",
            "With lambda = 1e-05\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 49.104 %\n",
            "\n",
            "With lambda = 0.0001\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 49.680000000000014 %\n",
            "\n",
            "With lambda = 0.001\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 49.872000000000014 %\n",
            "\n",
            "With lambda = 0.01\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 50.45000000000002 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIzK3SWqVK5w"
      },
      "source": [
        "## Sklearn Kernel Ridge regression results for comparaison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-Bc1OfiU5K-",
        "outputId": "f5a4e58c-85d8-408c-ec06-72da9ca8f5ef"
      },
      "source": [
        "### Compare with sklearn's Kernel ridge regression\n",
        "\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "\n",
        "n_iter = 100\n",
        "\n",
        "for i in range(len(gammas)):\n",
        "\n",
        "  # global gram matrix\n",
        "  K = Grams[i]\n",
        "\n",
        "  # center the Gram matrix\n",
        "  n = len(K)\n",
        "  I = np.eye(n)\n",
        "  U = np.ones((n,n)) / n\n",
        "  K = (I-U) @ K @ (I-U)\n",
        "\n",
        "  print(\"####################\\n\\nWith a gaussian kernel of parameter gamma = {}\\n\\n####################\".format(gammas[i]))\n",
        "\n",
        "  for lambd in [1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2]: \n",
        "\n",
        "    acc_train = 0\n",
        "    acc_valid = 0\n",
        "    \n",
        "    for it in range(n_iter):\n",
        "      K_train, y_train, K_valid_train, y_valid = train_test_split_on_gram(K, train_labels_0, train_frac=0.75)\n",
        "\n",
        "      #KRR predictions:\n",
        "      clf = KernelRidge(alpha=lambd * len(K_train), kernel=\"precomputed\").fit(K_train, remap_zero_minus_one(y_train))\n",
        "      y_train_pred = remap_minus_one_zero(np.sign(clf.predict(K_train)).astype(int))\n",
        "      y_valid_pred = remap_minus_one_zero(np.sign(clf.predict(K_valid_train)).astype(int))\n",
        "\n",
        "      # evaluation\n",
        "      acc_train += accuracy(y_train, y_train_pred)\n",
        "      acc_valid += accuracy(y_valid, y_valid_pred)\n",
        "    \n",
        "    acc_train /= n_iter\n",
        "    acc_valid /= n_iter\n",
        "\n",
        "    print(\"\\nWith lambda = {}\\n\".format(lambd))\n",
        "    print(\"Accuracy on the train set : {} %\".format((100 * acc_train)))\n",
        "    print(\"Accuracy on the validation set : {} %\".format((100 * acc_valid)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "####################\n",
            "\n",
            "With a gaussian kernel of parameter gamma = 0.001\n",
            "\n",
            "####################\n",
            "\n",
            "With lambda = 1e-08\n",
            "\n",
            "Accuracy on the train set : 65.98333333333335 %\n",
            "Accuracy on the validation set : 59.094 %\n",
            "\n",
            "With lambda = 1e-07\n",
            "\n",
            "Accuracy on the train set : 65.30799999999999 %\n",
            "Accuracy on the validation set : 59.30399999999998 %\n",
            "\n",
            "With lambda = 1e-06\n",
            "\n",
            "Accuracy on the train set : 63.16333333333334 %\n",
            "Accuracy on the validation set : 59.02 %\n",
            "\n",
            "With lambda = 1e-05\n",
            "\n",
            "Accuracy on the train set : 62.13199999999999 %\n",
            "Accuracy on the validation set : 58.628000000000014 %\n",
            "\n",
            "With lambda = 0.0001\n",
            "\n",
            "Accuracy on the train set : 62.03733333333332 %\n",
            "Accuracy on the validation set : 58.05999999999998 %\n",
            "\n",
            "With lambda = 0.001\n",
            "\n",
            "Accuracy on the train set : 61.783999999999985 %\n",
            "Accuracy on the validation set : 58.053999999999995 %\n",
            "\n",
            "With lambda = 0.01\n",
            "\n",
            "Accuracy on the train set : 61.901333333333305 %\n",
            "Accuracy on the validation set : 58.71200000000001 %\n",
            "####################\n",
            "\n",
            "With a gaussian kernel of parameter gamma = 0.01\n",
            "\n",
            "####################\n",
            "\n",
            "With lambda = 1e-08\n",
            "\n",
            "Accuracy on the train set : 66.52533333333335 %\n",
            "Accuracy on the validation set : 58.56399999999999 %\n",
            "\n",
            "With lambda = 1e-07\n",
            "\n",
            "Accuracy on the train set : 66.13666666666667 %\n",
            "Accuracy on the validation set : 58.93600000000002 %\n",
            "\n",
            "With lambda = 1e-06\n",
            "\n",
            "Accuracy on the train set : 65.47466666666666 %\n",
            "Accuracy on the validation set : 58.825999999999986 %\n",
            "\n",
            "With lambda = 1e-05\n",
            "\n",
            "Accuracy on the train set : 63.31200000000001 %\n",
            "Accuracy on the validation set : 58.86800000000001 %\n",
            "\n",
            "With lambda = 0.0001\n",
            "\n",
            "Accuracy on the train set : 62.25999999999999 %\n",
            "Accuracy on the validation set : 58.662000000000006 %\n",
            "\n",
            "With lambda = 0.001\n",
            "\n",
            "Accuracy on the train set : 61.962 %\n",
            "Accuracy on the validation set : 57.91399999999997 %\n",
            "\n",
            "With lambda = 0.01\n",
            "\n",
            "Accuracy on the train set : 61.70066666666667 %\n",
            "Accuracy on the validation set : 58.24999999999998 %\n",
            "####################\n",
            "\n",
            "With a gaussian kernel of parameter gamma = 0.1\n",
            "\n",
            "####################\n",
            "\n",
            "With lambda = 1e-08\n",
            "\n",
            "Accuracy on the train set : 81.90466666666667 %\n",
            "Accuracy on the validation set : 59.66999999999999 %\n",
            "\n",
            "With lambda = 1e-07\n",
            "\n",
            "Accuracy on the train set : 68.9673333333333 %\n",
            "Accuracy on the validation set : 59.240000000000016 %\n",
            "\n",
            "With lambda = 1e-06\n",
            "\n",
            "Accuracy on the train set : 66.516 %\n",
            "Accuracy on the validation set : 58.81199999999998 %\n",
            "\n",
            "With lambda = 1e-05\n",
            "\n",
            "Accuracy on the train set : 65.3686666666667 %\n",
            "Accuracy on the validation set : 59.174000000000014 %\n",
            "\n",
            "With lambda = 0.0001\n",
            "\n",
            "Accuracy on the train set : 63.14933333333334 %\n",
            "Accuracy on the validation set : 59.343999999999966 %\n",
            "\n",
            "With lambda = 0.001\n",
            "\n",
            "Accuracy on the train set : 62.20399999999998 %\n",
            "Accuracy on the validation set : 58.18599999999998 %\n",
            "\n",
            "With lambda = 0.01\n",
            "\n",
            "Accuracy on the train set : 62.087333333333326 %\n",
            "Accuracy on the validation set : 58.22200000000001 %\n",
            "####################\n",
            "\n",
            "With a gaussian kernel of parameter gamma = 1.0\n",
            "\n",
            "####################\n",
            "\n",
            "With lambda = 1e-08\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 57.16200000000001 %\n",
            "\n",
            "With lambda = 1e-07\n",
            "\n",
            "Accuracy on the train set : 99.01866666666662 %\n",
            "Accuracy on the validation set : 58.233999999999995 %\n",
            "\n",
            "With lambda = 1e-06\n",
            "\n",
            "Accuracy on the train set : 81.70733333333332 %\n",
            "Accuracy on the validation set : 59.36 %\n",
            "\n",
            "With lambda = 1e-05\n",
            "\n",
            "Accuracy on the train set : 69.08733333333335 %\n",
            "Accuracy on the validation set : 59.11000000000002 %\n",
            "\n",
            "With lambda = 0.0001\n",
            "\n",
            "Accuracy on the train set : 65.72933333333334 %\n",
            "Accuracy on the validation set : 59.524 %\n",
            "\n",
            "With lambda = 0.001\n",
            "\n",
            "Accuracy on the train set : 63.33266666666669 %\n",
            "Accuracy on the validation set : 59.04200000000003 %\n",
            "\n",
            "With lambda = 0.01\n",
            "\n",
            "Accuracy on the train set : 62.093333333333334 %\n",
            "Accuracy on the validation set : 58.66599999999998 %\n",
            "####################\n",
            "\n",
            "With a gaussian kernel of parameter gamma = 10.0\n",
            "\n",
            "####################\n",
            "\n",
            "With lambda = 1e-08\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 56.71199999999998 %\n",
            "\n",
            "With lambda = 1e-07\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 57.22800000000002 %\n",
            "\n",
            "With lambda = 1e-06\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 57.63799999999998 %\n",
            "\n",
            "With lambda = 1e-05\n",
            "\n",
            "Accuracy on the train set : 99.02999999999997 %\n",
            "Accuracy on the validation set : 58.520000000000024 %\n",
            "\n",
            "With lambda = 0.0001\n",
            "\n",
            "Accuracy on the train set : 81.39133333333335 %\n",
            "Accuracy on the validation set : 60.07799999999999 %\n",
            "\n",
            "With lambda = 0.001\n",
            "\n",
            "Accuracy on the train set : 68.49666666666666 %\n",
            "Accuracy on the validation set : 59.589999999999996 %\n",
            "\n",
            "With lambda = 0.01\n",
            "\n",
            "Accuracy on the train set : 63.917333333333325 %\n",
            "Accuracy on the validation set : 59.43400000000001 %\n",
            "####################\n",
            "\n",
            "With a gaussian kernel of parameter gamma = 100.0\n",
            "\n",
            "####################\n",
            "\n",
            "With lambda = 1e-08\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 59.21799999999999 %\n",
            "\n",
            "With lambda = 1e-07\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 58.838000000000015 %\n",
            "\n",
            "With lambda = 1e-06\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 59.278 %\n",
            "\n",
            "With lambda = 1e-05\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 58.97600000000002 %\n",
            "\n",
            "With lambda = 0.0001\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 59.72399999999997 %\n",
            "\n",
            "With lambda = 0.001\n",
            "\n",
            "Accuracy on the train set : 97.20133333333337 %\n",
            "Accuracy on the validation set : 60.56799999999999 %\n",
            "\n",
            "With lambda = 0.01\n",
            "\n",
            "Accuracy on the train set : 79.00399999999993 %\n",
            "Accuracy on the validation set : 60.287999999999975 %\n",
            "####################\n",
            "\n",
            "With a gaussian kernel of parameter gamma = 1000.0\n",
            "\n",
            "####################\n",
            "\n",
            "With lambda = 1e-08\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 49.16400000000002 %\n",
            "\n",
            "With lambda = 1e-07\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 49.263999999999996 %\n",
            "\n",
            "With lambda = 1e-06\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 49.183999999999976 %\n",
            "\n",
            "With lambda = 1e-05\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 49.22599999999999 %\n",
            "\n",
            "With lambda = 0.0001\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 49.56000000000002 %\n",
            "\n",
            "With lambda = 0.001\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 50.034 %\n",
            "\n",
            "With lambda = 0.01\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 50.32199999999999 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auSgAhu4WRPq"
      },
      "source": [
        "# 6. Spectrum Kernel for raw sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YSZOMvEW6aO"
      },
      "source": [
        "\n",
        "######################################################\n",
        "### SPECTRUM KERNEL\n",
        "######################################################\n",
        "\n",
        "def spectrum_kernel(x1,x2,k=6, normalize=False):\n",
        "    \n",
        "    # initialize the dictionaries of subsequences\n",
        "    phi1=dict()\n",
        "    phi2=dict()\n",
        "    \n",
        "    for i in range(len(x1)-k+1):\n",
        "        \n",
        "        # extract a subsequence of x1\n",
        "        subsequence = x1[i:k+i]\n",
        "        \n",
        "        # add the subsequence found to the dictionary 1\n",
        "        if subsequence not in phi1:\n",
        "            phi1[subsequence] = 1\n",
        "        else:\n",
        "            phi1[subsequence] += 1\n",
        "        \n",
        "    for i in range(len(x2)-k+1):\n",
        "\n",
        "        # extract a subsequence of x2\n",
        "        subsequence = x2[i:k+i]\n",
        "        \n",
        "        # add the subsequence found to the dictionary 2\n",
        "        if subsequence not in phi2:\n",
        "            phi2[subsequence]=1\n",
        "        else:\n",
        "            phi2[subsequence]+=1\n",
        "    \n",
        "    # compute the scalar product between the two representations obtained\n",
        "    scalar_prod = 0\n",
        "    for subsequence in phi1.keys() & phi2.keys():\n",
        "        scalar_prod += phi1[subsequence] * phi2[subsequence]\n",
        "    \n",
        "    if normalize:\n",
        "      norm_phi1 = ( sum(e**2 for e in phi1.values()) )**0.5\n",
        "      norm_phi2 = ( sum(e**2 for e in phi2.values()) )**0.5\n",
        "\n",
        "      scalar_prod /= (norm_phi1 * norm_phi2)\n",
        "    \n",
        "    return scalar_product\n",
        "\n",
        "\n",
        "\n",
        "#########################################################\n",
        "### FASTER IMPLEMENTATION TO COMPUTE THE GRAM MATRIX\n",
        "#########################################################\n",
        "\n",
        "def compute_spectrum_kernel_Gram(X,k=6, normalize=False):\n",
        "  \"\"\"\n",
        "  implement the function above but with ina  slightly more efficient version\n",
        "\n",
        "  In X, each row represents a sequence ('ATCGCTTGA...)\n",
        "  \"\"\"\n",
        "\n",
        "    # initialize the dictionaries of subsequences\n",
        "  phis = []\n",
        "  for sequence_id in range(len(X)):\n",
        "\n",
        "    phi = dict()\n",
        "    \n",
        "    for i in range(len(X[sequence_id])-k+1):\n",
        "        \n",
        "      # extract a subsequence\n",
        "      subsequence = X[sequence_id][i:k+i]\n",
        "      \n",
        "      # add the subsequence found to its dictionary \n",
        "      if subsequence not in phi:\n",
        "        phi[subsequence] = 1\n",
        "      else:\n",
        "        phi[subsequence] += 1\n",
        "\n",
        "    phis.append(phi)\n",
        "\n",
        "  norms_phis = np.array([(sum(e**2 for e in phis[i].values()))**0.5 for i in range(len(phis))]).reshape(1, -1)\n",
        "  \n",
        "  Gram = np.zeros((len(X),len(X)))\n",
        "  for i in range(len(X)):\n",
        "    for j in range(i+1,len(X)):\n",
        "\n",
        "      # compute the scalar products between the representations obtained\n",
        "      scalar_prod = 0\n",
        "      for subsequence in phis[i].keys() & phis[j].keys():\n",
        "        scalar_prod += phis[i][subsequence] * phis[j][subsequence]\n",
        "      \n",
        "      Gram[i,j] = scalar_prod\n",
        "      Gram[j,i] = scalar_prod\n",
        "  \n",
        "  if normalize:\n",
        "    Gram = Gram / np.repeat(norms_phis, len(X), axis=0)\n",
        "    Gram = Gram / np.repeat(norms_phis, len(X), axis=0).T\n",
        "    Gram = Gram + np.eye(len(X))\n",
        "  else:\n",
        "    Gram = Gram + np.diag(norms_phis.reshape(-1))\n",
        "  \n",
        "  return Gram\n",
        "\n",
        "\n",
        "\n",
        "#######################################################################\n",
        "### COMPUTE THE SUM OF GRAM MATRICES USING SUMS OF SPECTRUM KERNELS\n",
        "#######################################################################\n",
        "\n",
        "def compute_sum_spectrum_kernels_Gram(X, list_k, normalize=False):\n",
        "  \"\"\"\n",
        "  Allows to use the spectrum kernel for multiple subsequences-lenghts and sum the kernels\n",
        "  \"\"\"\n",
        "\n",
        "  Gram = np.zeros((len(X),len(X)))\n",
        "  for k in list_k:\n",
        "    Gram = Gram + compute_spectrum_kernel_Gram(X,k,normalize)\n",
        "\n",
        "  return Gram / len(list_k)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOmxwwnv3A_4"
      },
      "source": [
        "## Test KRR with spectrum kernel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gybKi7tqEcfX",
        "outputId": "05883048-65de-47d7-8c62-c31389a7e9e2"
      },
      "source": [
        "# Test KRR with gaussian kernel (and hyperparameters research)\n",
        "\n",
        "# global gram matrix\n",
        "\n",
        "K = compute_sum_spectrum_kernels_Gram(Xtr0, list_k=[6,7,8], normalize=True)\n",
        "\n",
        "n_iter = 100\n",
        "\n",
        "# center the Gram matrix\n",
        "n = len(K)\n",
        "I = np.eye(n)\n",
        "U = np.ones((n,n)) / n\n",
        "K = (I-U) @ K @ (I-U)\n",
        "\n",
        "print(\"####################\\n\\nWith a sum of spectrum kernels of parameters k = {}\\n\\n####################\".format(list_k))\n",
        "\n",
        "for lambd in [1e-4, 0.0003, 1e-3, 0.003, 1e-2, 0.03, 1e-1]: \n",
        "\n",
        "  acc_train = 0\n",
        "  acc_valid = 0\n",
        "  \n",
        "  for it in range(n_iter):\n",
        "    K_train, y_train, K_valid_train, y_valid = train_test_split_on_gram(K, train_labels_0, train_frac=0.75)\n",
        "\n",
        "    #KRR predictions:\n",
        "    alpha = kernelRidgeEstimator(K_train, y_train, lambd=lambd)\n",
        "    y_train_pred = predict_from_gram(K_train, alpha)\n",
        "    y_valid_pred = predict_from_gram(K_valid_train, alpha)\n",
        "\n",
        "    # evaluation\n",
        "    acc_train += accuracy(y_train, y_train_pred)\n",
        "    acc_valid += accuracy(y_valid, y_valid_pred)\n",
        "  \n",
        "  acc_train /= n_iter\n",
        "  acc_valid /= n_iter\n",
        "\n",
        "  print(\"\\nWith lambda = {}\\n\".format(lambd))\n",
        "  print(\"Accuracy on the train set : {} %\".format((100 * acc_train)))\n",
        "  print(\"Accuracy on the validation set : {} %\".format((100 * acc_valid)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "####################\n",
            "\n",
            "With a sum of spectrum kernels of parameters k = [5, 6, 7, 7, 8, 8]\n",
            "\n",
            "####################\n",
            "\n",
            "With lambda = 0.0001\n",
            "\n",
            "Accuracy on the train set : 100.0 %\n",
            "Accuracy on the validation set : 63.47600000000002 %\n",
            "\n",
            "With lambda = 0.0003\n",
            "\n",
            "Accuracy on the train set : 99.79000000000006 %\n",
            "Accuracy on the validation set : 64.052 %\n",
            "\n",
            "With lambda = 0.001\n",
            "\n",
            "Accuracy on the train set : 98.39066666666668 %\n",
            "Accuracy on the validation set : 64.42999999999999 %\n",
            "\n",
            "With lambda = 0.003\n",
            "\n",
            "Accuracy on the train set : 92.43400000000004 %\n",
            "Accuracy on the validation set : 64.514 %\n",
            "\n",
            "With lambda = 0.01\n",
            "\n",
            "Accuracy on the train set : 82.17066666666669 %\n",
            "Accuracy on the validation set : 62.694 %\n",
            "\n",
            "With lambda = 0.03\n",
            "\n",
            "Accuracy on the train set : 75.19600000000004 %\n",
            "Accuracy on the validation set : 62.18799999999997 %\n",
            "\n",
            "With lambda = 0.1\n",
            "\n",
            "Accuracy on the train set : 72.09333333333332 %\n",
            "Accuracy on the validation set : 61.682000000000016 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVr_lIZtdznq"
      },
      "source": [
        "#### The spectrum kernel on the raw DNA sequences is better than the Gaussian on the precomputed matrix.\n",
        "\n",
        "#### Plus, when we sum some spectrum kernels, we gat again better results.\n",
        "\n",
        "#### Doing Boostrap does not seem to enhance the classification, since we use less training samples each times, the neighbours are more far from the test samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsvqVDIs0_Kj"
      },
      "source": [
        "# predictions for dataset 0\n",
        "\n",
        "k_0 = [6,7,8]\n",
        "lambd_0 = 0.001\n",
        "\n",
        "X_te_plus_tr_0 = Xte0 + Xtr0\n",
        "\n",
        "K_te_plus_tr_0 = compute_sum_spectrum_kernels_Gram(X_te_plus_tr_0, k_0, normalize=True)\n",
        "\n",
        "\n",
        "# center the Gram matrix\n",
        "n = len(K_te_plus_tr_0)\n",
        "I = np.eye(n)\n",
        "U = np.ones((n,n)) / n\n",
        "K_te_plus_tr_0 = (I-U) @ K_te_plus_tr_0 @ (I-U)\n",
        "\n",
        "K_tr_0 = K_te_plus_tr_0[1000:,1000:]\n",
        "K_te_tr_0 = K_te_plus_tr_0[:1000,1000:]\n",
        "\n",
        "\n",
        "#KRR predictions:\n",
        "alpha_0 = kernelRidgeEstimator(K_tr_0, train_labels_0, lambd=lambd_0)\n",
        "\n",
        "y_pred_0 = predict_from_gram(K_te_tr_0, alpha_0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3_xAPbTnmhC"
      },
      "source": [
        "# predictions for dataset 1\n",
        "\n",
        "k_1 = [5,7,8]\n",
        "lambd_1 = 0.001\n",
        "\n",
        "X_te_plus_tr_1 = Xte1 + Xtr1\n",
        "\n",
        "K_te_plus_tr_1 = compute_sum_spectrum_kernels_Gram(X_te_plus_tr_1, k_1, normalize=True)\n",
        "\n",
        "\n",
        "# center the Gram matrix\n",
        "n = len(K_te_plus_tr_1)\n",
        "I = np.eye(n)\n",
        "U = np.ones((n,n)) / n\n",
        "K_te_plus_tr_1 = (I-U) @ K_te_plus_tr_1 @ (I-U)\n",
        "\n",
        "K_tr_1 = K_te_plus_tr_1[1000:,1000:]\n",
        "K_te_tr_1 = K_te_plus_tr_1[:1000,1000:]\n",
        "\n",
        "\n",
        "#KRR predictions:\n",
        "alpha_1 = kernelRidgeEstimator(K_tr_1, train_labels_1, lambd=lambd_1)\n",
        "\n",
        "y_pred_1 = predict_from_gram(K_te_tr_1, alpha_1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4vXEM8KmkaR"
      },
      "source": [
        "# predictions for dataset 2\n",
        "\n",
        "k_2 = [6,8]\n",
        "lambd_2 = 0.0003\n",
        "\n",
        "X_te_plus_tr_2 = Xte2 + Xtr2\n",
        "\n",
        "K_te_plus_tr_2 = compute_sum_spectrum_kernels_Gram(X_te_plus_tr_2, k_2, normalize=True)\n",
        "\n",
        "\n",
        "# center the Gram matrix\n",
        "n = len(K_te_plus_tr_2)\n",
        "I = np.eye(n)\n",
        "U = np.ones((n,n)) / n\n",
        "K_te_plus_tr_2 = (I-U) @ K_te_plus_tr_2 @ (I-U)\n",
        "\n",
        "K_tr_2 = K_te_plus_tr_2[1000:,1000:]\n",
        "K_te_tr_2 = K_te_plus_tr_2[:1000,1000:]\n",
        "\n",
        "\n",
        "#KRR predictions:\n",
        "alpha_2 = kernelRidgeEstimator(K_tr_2, train_labels_2, lambd=lambd_2)\n",
        "\n",
        "y_pred_2 = predict_from_gram(K_te_tr_2, alpha_2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfZN30EV0_Hw"
      },
      "source": [
        "\n",
        "export_predict(y_pred_0,y_pred_1,y_pred_2,'preds_sum_kernels.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFMtxVev1yZH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmJHDS_E_DPp"
      },
      "source": [
        "### Ensemble methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOm6b3YY_BOW"
      },
      "source": [
        "# predictions for dataset 0\n",
        "\n",
        "k_0 = [6,7,8]\n",
        "lambd_0 = 0.001\n",
        "\n",
        "\n",
        "X_te_plus_tr_0 = Xte0 + Xtr0\n",
        "\n",
        "K_te_plus_tr_0 = compute_sum_spectrum_kernels_Gram(X_te_plus_tr_0, k_0, normalize=True)\n",
        "\n",
        "y_pred_0 = []\n",
        "\n",
        "for n_model in range(15):\n",
        "\n",
        "  shuffle = np.random.permutation(2000)\n",
        "  last_train = int(0.75*2000)\n",
        "  idxs_train = shuffle[:last_train]\n",
        "  idxs = np.concatenate([np.arange(1000), 1000+idxs_train])\n",
        "\n",
        "  K_te_plus_part_tr_0 = K_te_plus_tr_0[idxs].T[idxs].T\n",
        "  part_train_labels_0 = train_labels_0[idxs_train]\n",
        "\n",
        "  # center the Gram matrix\n",
        "  n = len(K_te_plus_part_tr_0)\n",
        "  I = np.eye(n)\n",
        "  U = np.ones((n,n)) / n\n",
        "  K_te_plus_part_tr_0 = (I-U) @ K_te_plus_part_tr_0 @ (I-U)\n",
        "\n",
        "  K_part_tr_0 = K_te_plus_part_tr_0[1000:,1000:]\n",
        "  K_te_part_tr_0 = K_te_plus_part_tr_0[:1000,1000:]\n",
        "\n",
        "\n",
        "  #KRR predictions:\n",
        "  alpha_0 = kernelRidgeEstimator(K_part_tr_0, part_train_labels_0, lambd=lambd_0)\n",
        "\n",
        "  y_pred_0.append(predict_from_gram(K_te_part_tr_0, alpha_0))\n",
        "\n",
        "y_pred_0 = np.array(y_pred_0)\n",
        "y_pred_merged_0 = np.round(y_pred_0.mean(axis=0)).astype(int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTALb46n_A_S"
      },
      "source": [
        "# predictions for dataset 1\n",
        "\n",
        "k_1 = [5,7,8]\n",
        "lambd_1 = 0.001\n",
        "\n",
        "\n",
        "X_te_plus_tr_1 = Xte1 + Xtr1\n",
        "\n",
        "K_te_plus_tr_1 = compute_sum_spectrum_kernels_Gram(X_te_plus_tr_1, k_1, normalize=True)\n",
        "\n",
        "y_pred_1 = []\n",
        "\n",
        "for n_model in range(15):\n",
        "\n",
        "  shuffle = np.random.permutation(2000)\n",
        "  last_train = int(0.75*2000)\n",
        "  idxs_train = shuffle[:last_train]\n",
        "  idxs = np.concatenate([np.arange(1000), 1000+idxs_train])\n",
        "\n",
        "  K_te_plus_part_tr_1 = K_te_plus_tr_1[idxs].T[idxs].T\n",
        "  part_train_labels_1 = train_labels_1[idxs_train]\n",
        "\n",
        "  # center the Gram matrix\n",
        "  n = len(K_te_plus_part_tr_1)\n",
        "  I = np.eye(n)\n",
        "  U = np.ones((n,n)) / n\n",
        "  K_te_plus_part_tr_1 = (I-U) @ K_te_plus_part_tr_1 @ (I-U)\n",
        "\n",
        "  K_part_tr_1 = K_te_plus_part_tr_1[1000:,1000:]\n",
        "  K_te_part_tr_1 = K_te_plus_part_tr_1[:1000,1000:]\n",
        "\n",
        "\n",
        "  #KRR predictions:\n",
        "  alpha_1 = kernelRidgeEstimator(K_part_tr_1, part_train_labels_1, lambd=lambd_1)\n",
        "\n",
        "  y_pred_1.append(predict_from_gram(K_te_part_tr_1, alpha_1))\n",
        "\n",
        "y_pred_1 = np.array(y_pred_1)\n",
        "y_pred_merged_1 = np.round(y_pred_1.mean(axis=0)).astype(int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eqECv0MD9Kq"
      },
      "source": [
        "# predictions for dataset 2\n",
        "\n",
        "k_2 = [6,8]\n",
        "lambd_2 = 0.0003\n",
        "\n",
        "\n",
        "X_te_plus_tr_2 = Xte2 + Xtr2\n",
        "\n",
        "K_te_plus_tr_2 = compute_sum_spectrum_kernels_Gram(X_te_plus_tr_2, k_2, normalize=True)\n",
        "\n",
        "y_pred_2 = []\n",
        "\n",
        "for n_model in range(15):\n",
        "\n",
        "  shuffle = np.random.permutation(2000)\n",
        "  last_train = int(0.75*2000)\n",
        "  idxs_train = shuffle[:last_train]\n",
        "  idxs = np.concatenate([np.arange(1000), 1000+idxs_train])\n",
        "\n",
        "  K_te_plus_part_tr_2 = K_te_plus_tr_2[idxs].T[idxs].T\n",
        "  part_train_labels_2 = train_labels_2[idxs_train]\n",
        "\n",
        "  # center the Gram matrix\n",
        "  n = len(K_te_plus_part_tr_2)\n",
        "  I = np.eye(n)\n",
        "  U = np.ones((n,n)) / n\n",
        "  K_te_plus_part_tr_2 = (I-U) @ K_te_plus_part_tr_2 @ (I-U)\n",
        "\n",
        "  K_part_tr_2 = K_te_plus_part_tr_2[1000:,1000:]\n",
        "  K_te_part_tr_2 = K_te_plus_part_tr_2[:1000,1000:]\n",
        "\n",
        "\n",
        "  #KRR predictions:\n",
        "  alpha_2 = kernelRidgeEstimator(K_part_tr_2, part_train_labels_2, lambd=lambd_2)\n",
        "\n",
        "  y_pred_2.append(predict_from_gram(K_te_part_tr_2, alpha_2))\n",
        "\n",
        "y_pred_2 = np.array(y_pred_2)\n",
        "y_pred_merged_2 = np.round(y_pred_2.mean(axis=0)).astype(int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8Le9_zdEfDe"
      },
      "source": [
        "\n",
        "export_predict(y_pred_merged_0,y_pred_merged_1,y_pred_merged_2,'preds_sum_kernels_ensemble.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
